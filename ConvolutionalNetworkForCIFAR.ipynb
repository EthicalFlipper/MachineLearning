{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyyq3hfuJuqIQbFIYVUkmN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EthicalFlipper/MachineLearning/blob/main/ConvolutionalNetworkForCIFAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "mKlNGqpiXyeI",
        "outputId": "684255a1-98fb-46bd-89f0-e6225cc5eb33"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAAD7CAYAAACL3GNOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAS5klEQVR4nO2dzZMd5XXGz3s/5kOaERoNSAJ9YkQoAo7L5TgVV7JIJanKLqnCSSUL+z/wwquksmMZb7LKX5APF4lJlZNFsnY5izgUGGIwYAQGCwQIhMR8z723+81CkyoW/TziNoPFwb/fytWHt/u9fe8zLZ+nzzml1hoA8NlncKc3AAAfD8QKkATECpAExAqQBMQKkATECpAExPo5oZTyeCnlH038hVLK7/0StwSHzOhObwB+OdRaH7nTe4BPBk9WgCQg1oSUUv6qlPJWKWWzlPJyKeUPDkILpZS/Pzj+QinlNz+y5vVSyh8e/O/HSylPllL++eC/faaU8qU78mHgY4NYk1FKeSgivhURX621rkbEH0XE6wfhP46IJyLieET8e0T8nTnVn0TE9yLiRER8NyK+X0oZf0rbhkMAseajiYjFiPj1Usq41vp6rfXVg9h/1Vr/o9baRMQ/RIR7Wj5da32y1jqNiL+NiKWI+O1PdefwiUCsyai1Xo6Ib0fE4xFxrZTyRCnlvoPwOx/5T3ciYqmUopKIVz5yzjYi3oyI+8R/C58BEGtCaq3frbX+bkRciIgaEd/pcZpz//8/SimDiDgbEVcPZ4fwaYBYk1FKeaiU8vullMWI2IuI3Yhoe5zqK6WUxw6evN+OiP2I+O9D3CocMog1H4sR8TcR8X7c+mfvyYj46x7n+beI+POIuBER34yIxw7+/yt8RikUn//qUUp5PCIu1Vq/caf3Ah8fnqwASUCsAEngn8EASeDJCpAExAqQhLlK5NZOrNcz5y50xg77n9PubH2vpVa501W3E7sNHfTX67GPftu4XXDuJdbs7X0bVbQc8vk+AX3OKZZcf+9qbG3c7Pxwc4n1zLkL8S//+YPOWNvO78s35jPOGn0+dy0Xm4rrTVu9kaZpeu5Dn9Pdqmkz6zw+Mz/BtuoTFrOPajai/iC6P5STmf6HWuP2Yc6p7n+tRqzm/vb5nUZEVPN7LFP9G5l3H9/5y2/KNfwzGCAJiBUgCYgVIAmIFSAJczZMq1FEokMddxST0Ss6FAMTNHkH+ZfJXcvGzJ+6gduIuVfqsw3NRorJmZRiElNmiyr77JJZw4H7zBqbjJMRcw8HQ72qR1LtIChDxf1IBAN1r3r8fgHgMwZiBUgCYgVIAmIFSAJiBUgCYgVIwtyzbgYymT5/kn1gvA/3V8S5Is5AUtnygbE3qonZl9PdOpPql+6Hs0XsfTSWgz5jtPJdWL1q6E7Yw964dU7xjrL5hTh7xt1GZ0uF+T6dPaboU4zCkxUgCYgVIAmIFSAJiBUgCYgVIAk9Jp/rxiMKlYBz+UGXxWxN5tlldgciZDPPJmZbt/RswyIzqi5j7V5qt3d5/tYotojCXEne/Aj7krxO0JruEuZ8I/Nluwyz+8316aqhqy/cdwkAKUCsAElArABJQKwASUCsAElArABJmNu6Uf1m+nQccjaLtWecTWQ2olL6tnWQCVbTO8il4F2volK6+we1ovl3RMTAvhTe7wV6tcrZEbanllnn7KCheJw0M9MLSi0Kv/+258v6qo7C9ZaSPZjMPeTJCpAExAqQBMQKkATECpAExAqQBMQKkIS5rJsSt7MJuukzINjaOnYPZo6muJ7/i2UsGGs9uSoZs0dZGdSvT5Q3bvpU5LiqG7cPE7N2UDe2Usqer2/10vz339k9eo9U3QCkB7ECJAGxAiQBsQIkAbECJAGxAiTh0Caf2xEU4njrKgwGrnKiMTEZkhaBm36gx4XcpimaG9OgQxFi9IO5HaapmJ/KbSdaqGDPhmnV7qNHRY4ebm7vhx2vYoKte6yJ65mpJvIp6b4TnqwASUCsAElArABJQKwASUCsAElArABJOLRZN9YiUGfq2UTL2QB9JkrfbqKNwtsirsrE7ET4Ds7Kat1QdOcF9FjnzucrU/S1fPWVCNjfh7mW7S3Xby6QsnWK+2Lk10nDNID0IFaAJCBWgCQgVoAkIFaAJPTIBndnq3plYe178Ifbs8fF/PvsNmXaK9baLLJ6Q91kCV162d7k+ceQuCy3TcPazzz/iA/b3+hTuB9+irk43Hv0Sjc8WQGSgFgBkoBYAZKAWAGSgFgBkoBYAZIwp3VTooo8dSN6B32WGPboK+Qy/dWk5qeuEdBA3/aB+PvpRoYMzSZndar3YSih+lyZnlTSdopoq3kuuEnl4nfVms/VFtOjq+cYklbeD223FdeESf0+6MEEkB/ECpAExAqQBMQKkATECpAExAqQhB5VN924uol+HY4OH+W0uKqP1lhSrbFnXNWQH8khejDZqqaedoT5bKqSx1a09Nyj+/XoFkyHW8Vza6H5zlwFjfrcPavD5B56rAGAOwBiBUgCYgVIAmIFSAJiBUgCYgVIQo/J56paoF+Dsz7IPdwmVnv8beptA7jRIHY0t6gycZ/LTm43l+oxuX3oqkLM53LWk7vHyspyVpD7xlpnc7lzWnuvO+assaHYpds7T1aAJCBWgCQgVoAkIFaAJCBWgCQgVoAkzF91I1LwxdoRc1+l1x5uGxM2gN16v9EovSprbl1PVN0YG8B/YhNtZzI0FJPWnYU0dJdyto5pLKaqfNysG/eZG7MPb2VpU6UR62qrm6wNh6LJmt4BT1aALCBWgCQgVoAkIFaAJCBWgCQgVoAkzG3dKEvCFaeotL0d/W5wNpGzTKJ2b7KK4wdBsxNTpWHS9iNzs0ZiXIyyByL8TJWRafQ1Mbeqrd37d/d+6CwYN/bFNZ4T97+K/UVEDHpWzzhbx/d7U534zBp5LddoDwBSgFgBkoBYAZKAWAGSgFgBkjBXNvjW3PPubJUbLxBt9xqbfXP0HVshsnZ2GnaPPkURMvEcERHbWx/K2PXr73cen07NBHOT4Vw8sqrXGVaOrnQebxqThR0tyZjLSs9muqBAOQbuKWOLF3pmW20hglhZzER3159JXwcAUoBYAZKAWAGSgFgBkoBYAZKAWAGSMPeL/MoacSMy5JqezZn8uvl7MNlxC+aFfHepQdGp+VdffkHGnnrqqc7j+/v7cs1kom2daRWVARHxpS9/Wca++OijnceddXN0bVHGGmHfRYRtZqUsE/dC/tTYLI2xiVTfqQj/+1ZFBa7AQkzcoAcTwOcBxAqQBMQKkATECpAExAqQBMQKkIT5rJtqplubVLpKe9sJ4HYfbvyEsQFEKt2NwehrL9VGWwSn7j4hYxfO3td5fGBshesffCBjk1ZbNyPzwV/66fOdxy9detCcT4bC9qty1o2IOQvJjfEYmEoY91U3bo/Ch3GFaNrO1PBkBUgCYgVIAmIFSAJiBUgCYgVIAmIFSML8k88FNmt/6KPPDxc3+sNN5TahmOzpSpjFBX3bH3rwgc7jq6u68dnTTz8jYwsrazK2vbsrY8oCO7F2l1xjm5E5G8PYUmq0RnVVPAb7O7W/A/8L76I19pJqmOamtfBkBUgCYgVIAmIFSAJiBUgCYgVIAmIFSEKPhmnduEZUshLGpOxtgy1nBZmJ2CW6Y65Sx03lbs0er117W8Z+8tyPZWxvb6/z+JVf/EKuGY7013j/JR27+tZVGfva136n87ir/mnMPJ7hQFf/VDP3pRW/q7GpnmnMz8POmHE/K/e7EltxTdaiVXph8jlAehArQBIQK0ASECtAEhArQBLmzAbXaEQ2zWbZxEvQrXlz2k0ONwlJ259p1nRnK9213PvbjemztH6PfoE+xvq2D6N7BMXq+rq+1rru6TRpJjJ29W2dDT556nTn8VJ0Vtf2q3LZfZM1VV916zKt5ktrxQiVW8vM79Gsq+Jz2zUD1cuMbDBAehArQBIQK0ASECtAEhArQBIQK0AS5rJuatVjC3zau5vGTBV34xFG4oX8CG8fDMTL5M5VcC+u33XsmIy9/MorMnby3rMytr293Xl89bi2bra2tmTsnavanrn8+hsy9sST/9p5/M/+9C/kmsWFJRlz1p5z/SZT0avINHVyMVcgYtssmd+B6rU0c9e6Tdeyzi3MvQIA7giIFSAJiBUgCYgVIAmIFSAJiBUgCXNaNzX2prrSxK3rYmCqT8JULDSyf03EbNLdwygiYjhcEFfSf7PeMPbGtWvvydjWzo6MTVxViPAxZsbKGiwuy9jpM+dk7OzF7lEdERHLK9221MKRo3JN49obmWqdWdXf57747SwOx/parl+SsxhtLy4ZkvbewFg3rreXvM7cKwDgjoBYAZKAWAGSgFgBkoBYAZKAWAGSMJd1s7O7G88897+dMdc8TFXQjM0E8MWxaczV6jENR5e7G45FRAwG3dZNHeg1zzzzrIw9++xzMnZzc1PGTl24KGNnz3ZX5Fy+fFmuWTfN1M6fPy9jDzz4kIxdFLbOu+9dl2v2RYVMhLdM9if7MqYmz4/M+IxBcbaIqXYx/szUjIdRdWXO7lE0xv/iyQqQBMQKkATECpAExAqQBMQKkATECpCEuaybWTOLDz682RlbXtaVHyMxmXtkqm6KmgUSEReNHXH82KqMLS2vdB5/9edv6vMdv0vGHnjgfhm7saGbmB072T1HJiLiRz/6n87jV97Ue5yZieNf//pjMra2pmfkvPTiS53H331HWzcTV3ZjGo7tmAql8VhU15gua0MzL8ZZI8U1WjPWTRH2krMzla2zva3vBU9WgCQgVoAkIFaAJCBWgCQgVoAkzD0+Q72rPTVZrLW17ingi0vdL9ZHRJy6W08OH5ss8sZGd7Y6ImJzq3s0RRTds+fXHtJ9is6c0Vndm5s6G3xjR08j/62vfqXz+G988RF9rZv6My+Ze3z8uB7/sbu923l8e2tDromR7ovUmJ5DbpJ9Iya3V9PfyGWl+/RSioiY9cgGuzWq35PrA8WTFSAJiBUgCYgVIAmIFSAJiBUgCYgVIAlzWTdRBjEQ6fnr1/UL3pvCBnh194ZcszjUKey717Tl4F7iDpFiXzqiX/53xQbNTFs+Lm3v/kKeP3tv5/HhUPekUoUSEX6C/GRfFwDcd/qezuNXruhJ6otHdTGH82c2NrQdNJkI66bq86lp6RERw5G+j+5l/akZG6OsGzdJvYpeUK5tE09WgCQgVoAkIFaAJCBWgCQgVoAkIFaAJMxn3UREFWnqE3d3p/ojIqaiR1Cz/6G+TtW2wvLykowNzMT0gRi50IS+1vaOqNSJiOlEr9ufmHEira5OmYjcvbNuXKXGyFgVQzM9fEGMGnnggp6krvYeETEzPZMaM62+Nt332DgpUcy9UjZLRERj9qisloiImbDwnKXWMvkc4PMLYgVIAmIFSAJiBUgCYgVIAmIFSMJc1k3bttLKcGlqNfXaNewqM53OHw50an6yr6doL426J5yPrb3hJqnLkLcIZvp6rbAPXAWHm+bdzIy9ZO7V1mb3/R8Zu2fpmP4+J2aUxMn14zLWTrsrtjbN+cZmj8XWtegKpTIwU9H3u+9VU/X3rKp4qrGPeLICJAGxAiQBsQIkAbECJAGxAiQBsQIkYU7rpok9Yd2smynaKoGtrJSIiLPnz8rY4oJOzb/44k9l7K2r73YeX145Ktesr6/L2HioG4SVBdOoLEzJiPj72Zr5LaqaKCJiZCykaqbLl+Xu2L5oYBYRUad6vs/AzKYZjrT1dPzokc7jezvvyzXtZFPGnE23vqK/z9OnTspYFXbQu+/oPTZN97UWRvr74skKkATECpAExAqQBMQKkATECpAExAqQhLmsm/F4HKfu6U5h727rxmIDUZHz6KOPyDXnz56Wsc0NnZo/cmRFxnb2uis4Lv/8NbnmlZ+9KmOu0mhtbU3Gjh7Ve1TNz44ICyMiYizmD0VEFO0g2Vk9y0vd1sLenq6G2p3qWGsqWjZu6JlHJ092z/5ZMXbbyqq+V+fuPSVjZ+7V9szC2FRK1e7P9v77uiHg5kb3b/H73/snuYYnK0ASECtAEhArQBIQK0ASECtAEubKBte2yknU7gXv/d3uzNezz/5YrnnhJ3ofA9P8yE0qv3DxYufxhx9+WK7Z2tIvpz///PMy9tprOsN848ZNGVtcFH2ixjrj62LLY10ssTDuHpEREbGw0B1z12rs6BL9vQyHeh/nxaiU86cvyDXnLugikLvMdPYlk/Et5rPtT7p7WS0urso1Gys7ncfH5jvhyQqQBMQKkATECpAExAqQBMQKkATECpCE+aybqHJi87FVnabe3+m2bq6+fUWu2dnU9oazU8bCcoiI+MEPf9h5fEHYJRHeqlD2RkTEmTNnZGwy+ZmMqQnnKyv65f+RmfTdmhHh6gX0iIgNcf/dWBA3ImN3T1t7X7j/kozdEC/5q6KMiIjxgr4fq1/Qls9goOXQzLR188H17nu1tKQLCtbXuws93KR6nqwASUCsAElArABJQKwASUCsAElArABJKKrnT+d/XMp7EfHGp7cdgF95LtRa7+kKzCVWALhz8M9ggCQgVoAkIFaAJCBWgCQgVoAkIFaAJCBWgCQgVoAkIFaAJPwfWxrxztMvjdsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min max value in image 30 242\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min max value in image 0.11764706 0.9490196\n"
          ]
        }
      ],
      "source": [
        "#Keras to create the neural network\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "#Matplotlib to plot info to show our results\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "img_rows, img_cols = 32, 32 #Variables to help keep track of image size (32 by 32 pixels)\n",
        "num_classes = 10 #Output classes\n",
        "input_shape = (img_rows, img_cols, 3) #Keep track of what shape the data is\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data() #This line will load data to train the model, and data to test it, as well as the labels to test the data\n",
        "(train_images_backup, train_labels_backup), (test_images_backup, test_labels_backup) = cifar10.load_data() #This line will load data to train the model, and data to test it, as well as the labels to test the data (backup)\n",
        "\n",
        "label_names= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] #Array of labels\n",
        "train_labels_backup = [item for sublist in train_labels_backup for item in sublist] #Convert the label arrays\n",
        "test_labels_backup = [item for sublist in test_labels_backup for item in sublist] #Convert the label arrays\n",
        "\n",
        "#Helper functions\n",
        "def show_min_max(array, i): #Array = train_images, i = 100\n",
        "  random_image = array[i] #Pick random image out of 100\n",
        "  print(\"min max value in image\", random_image.min(), random_image.max())\n",
        "\n",
        "def plot_image(array, i, labels):\n",
        "  plt.imshow(np.squeeze(array[i]))\n",
        "  plt.title(str(label_names[labels[i]]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show() #Show the image\n",
        "\n",
        "plot_image(train_images, 100, train_labels_backup) #Call plot_image function and pass it train_images, 100, test_images\n",
        "show_min_max(train_images, 100) #Print out the 100th image\n",
        "\n",
        "# Print out the shape of the train and test images to make sure it matches the expectations\n",
        "print(train_images.shape) \n",
        "print(test_images.shape)\n",
        "\n",
        "train_images = train_images.astype('float32') #Convert data into float32\n",
        "test_images = test_images.astype('float32') #Convert data into float32\n",
        "\n",
        "train_images /= 255 #Divide by 255 so each pixel is stored by value 0-1\n",
        "test_images /= 255 #Divide by 255 so each pixel is stored by value 0-1\n",
        "\n",
        "#Print out the image and min/max values again to make sure it is normalized\n",
        "plot_image(train_images, 100, train_labels_backup)\n",
        "show_min_max(train_images, 100)\n",
        "\n",
        "train_labels = keras.utils.to_categorical(train_labels, num_classes) #Employ one-hot encoding on your data. One-hot encoding makes the network view each number independently\n",
        "test_labels = keras.utils.to_categorical(test_labels, num_classes) #Employ one-hot encoding on your data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "#Number of epochs\n",
        "epochs = 20\n",
        "#Batch size\n",
        "batch_size = 64\n",
        "#Model\n",
        "model = Sequential()\n",
        "\n",
        "#Convolutional layer with 32, 3x3 pixel filters\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', input_shape = input_shape))\n",
        "#Convolutional layer with 64 filters\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "#Pooling layer - condense the information the network has learned so far\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "#Dropout layer - so network doesn't get too dependent or specific\n",
        "model.add(Dropout(rate = 0.2))\n",
        "#Batch normalization layer - Batch normalization helps to keep each layer on the right track and working towards the desired goal\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#Convolutional Layer\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "#Pooling Layer\n",
        "model.add(MaxPooling2D(pool_size = (1, 1)))\n",
        "#Dropout Layer\n",
        "model.add(Dropout(rate = 0.3))\n",
        "#Batch Normalization layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#Convolutional Layer\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu'))\n",
        "#Final Convolutional Layer\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "#Final Pooling Layer\n",
        "model.add(MaxPooling2D(pool_size = (1, 1)))\n",
        "#Final Dropout Layer\n",
        "model.add(Dropout(rate = 0.3))\n",
        "#Final Batch Normalization Layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#Flatten Layer - start to prepare the network to produce output\n",
        "model.add(Flatten())\n",
        "#Dense Layer\n",
        "model.add(Dense(units = 128, activation = 'relu'))\n",
        "#Output Layer\n",
        "model.add(Dense(units = num_classes, activation = 'softmax'))\n",
        "#Summary\n",
        "model.summary()\n",
        "#Compile\n",
        "model.compile(loss = keras.losses.categorical_crossentropy, optimizer = 'adam', metrics = ['accuracy'])\n",
        "#Fit\n",
        "model.fit(train_images, train_labels, batch_size = batch_size, epochs = epochs, validation_data = (test_images, test_labels), shuffle = True)\n",
        "#Evaluate\n",
        "scores = model.evaluate(test_images, test_labels, verbose = 0) \n",
        "print('Test accuracy:', scores[1])\n",
        "#Save\n",
        "model.save('cifar_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fqp4Jpzednw",
        "outputId": "132cef19-ca9e-4b4f-fce9-79f124b382b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 12, 12, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 12, 12, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 12, 12, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 10, 10, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 8, 8, 64)          73792     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 8, 8, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               524416    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 730,442\n",
            "Trainable params: 730,058\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 354s 452ms/step - loss: 1.5557 - accuracy: 0.4504 - val_loss: 1.3658 - val_accuracy: 0.5209\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 338s 432ms/step - loss: 1.1092 - accuracy: 0.6035 - val_loss: 1.1421 - val_accuracy: 0.5998\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 342s 437ms/step - loss: 0.9233 - accuracy: 0.6726 - val_loss: 1.0119 - val_accuracy: 0.6570\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 336s 430ms/step - loss: 0.8023 - accuracy: 0.7174 - val_loss: 0.8723 - val_accuracy: 0.7012\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 336s 430ms/step - loss: 0.7264 - accuracy: 0.7440 - val_loss: 0.9582 - val_accuracy: 0.6816\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 336s 429ms/step - loss: 0.6651 - accuracy: 0.7652 - val_loss: 0.8942 - val_accuracy: 0.6880\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 337s 431ms/step - loss: 0.6188 - accuracy: 0.7788 - val_loss: 0.7580 - val_accuracy: 0.7425\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 336s 429ms/step - loss: 0.5742 - accuracy: 0.7964 - val_loss: 0.8127 - val_accuracy: 0.7299\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 335s 428ms/step - loss: 0.5399 - accuracy: 0.8090 - val_loss: 0.7138 - val_accuracy: 0.7692\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 337s 431ms/step - loss: 0.4983 - accuracy: 0.8231 - val_loss: 0.7105 - val_accuracy: 0.7626\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 336s 430ms/step - loss: 0.4645 - accuracy: 0.8345 - val_loss: 0.7264 - val_accuracy: 0.7629\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 335s 428ms/step - loss: 0.4368 - accuracy: 0.8444 - val_loss: 0.7734 - val_accuracy: 0.7587\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 353s 452ms/step - loss: 0.4157 - accuracy: 0.8527 - val_loss: 1.4576 - val_accuracy: 0.7280\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 347s 444ms/step - loss: 0.3909 - accuracy: 0.8613 - val_loss: 0.7780 - val_accuracy: 0.7512\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 366s 468ms/step - loss: 0.3694 - accuracy: 0.8667 - val_loss: 0.7307 - val_accuracy: 0.7825\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 366s 469ms/step - loss: 0.3477 - accuracy: 0.8766 - val_loss: 0.7979 - val_accuracy: 0.7517\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 366s 468ms/step - loss: 0.3359 - accuracy: 0.8793 - val_loss: 0.7869 - val_accuracy: 0.7700\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 360s 460ms/step - loss: 0.3152 - accuracy: 0.8878 - val_loss: 0.7219 - val_accuracy: 0.7863\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 336s 430ms/step - loss: 0.3057 - accuracy: 0.8908 - val_loss: 0.8105 - val_accuracy: 0.7702\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 337s 431ms/step - loss: 0.2924 - accuracy: 0.8955 - val_loss: 0.7706 - val_accuracy: 0.7878\n",
            "Test accuracy: 0.7878000140190125\n"
          ]
        }
      ]
    }
  ]
}